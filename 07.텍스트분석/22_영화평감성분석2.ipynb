{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버 영화평 감성분석\n",
    "- Tokenizer 함수\n",
    "- TfidfVectorizer + LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/naver_movie_train_전처리완료.tsv', sep='\\t')\n",
    "test_df = pd.read_csv('./data/naver_movie_test_전처리완료.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((145393, 3), (48852, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tokenizer 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','을','ㅋㅋ','ㅠㅠ','ㅎㅎ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def okt_tokenizer(text):\n",
    "    morphs = okt.morphs(text, stem=True)\n",
    "    tokens = [word for word in morphs if word not in stopwords]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['열심히', '일', '당신', '주말', '엔', '여행', '떠나다', '보다', '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt_tokenizer('열심히 일한 당신 주말엔 여행을 떠나봐요.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pipeline으로 피쳐 변환과 분류를 동시에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('TFIDF',\n",
       "                 TfidfVectorizer(tokenizer=<function okt_tokenizer at 0x000001E4404645E0>)),\n",
       "                ('LR', LogisticRegression(random_state=2022))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('TFIDF',TfidfVectorizer(tokenizer=okt_tokenizer)),\n",
    "    ('LR',LogisticRegression(random_state=2022))\n",
    "])\n",
    "pipeline.fit(train_df.document, train_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8427290591992139"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(test_df.document, test_df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실제 데이터 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "reviews = ['모든 국민이 봤으면 하는 영화입니다.',\n",
    "           '생각보다 지루하고 별로였네요... 보면서 좀 졸았습니다.']\n",
    "reviews = map(lambda x: re.sub('[^가-힣]',' ',x), reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최적 파라메터 찾기\n",
    "    - 매 시행시마다 한글 형태소 분석을 하느라 시간이 너무 오래 걸림\n",
    "    - 최적 파라메터를 찾으려고 하면 한글 형태소 분석을 한 데이터로 할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\n",
    "    'TFIDF__ngram_range': [(1,1),(1,2)],\n",
    "    'TFIDF__max_df': [0.95, 0.98],\n",
    "    'LR__C': [1,5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_pipe = GridSearchCV(pipeline, params, scoring='accuracy', cv=3)\n",
    "# grid_pipe.fit(train_df.document, train_df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CountVectorizer 사례에서 찾은 최적의 파라메터로 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6min 16s\n",
      "Wall time: 5min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('TFIDF',\n",
       "                 TfidfVectorizer(max_df=0.95, ngram_range=(1, 2),\n",
       "                                 tokenizer=<function okt_tokenizer at 0x000001E4404645E0>)),\n",
       "                ('LR', LogisticRegression(random_state=2022))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('TFIDF', TfidfVectorizer(tokenizer=okt_tokenizer, max_df=0.95, ngram_range=(1,2))),\n",
    "    ('LR', LogisticRegression(random_state=2022))\n",
    "])\n",
    "%time pipeline.fit(train_df.document, train_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8583476623270285"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(test_df.document, test_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "becefdacc5f1c94720c81594b94a76de7b81d1f18fcb450ac2dbe2941d580a00"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('kdig')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
