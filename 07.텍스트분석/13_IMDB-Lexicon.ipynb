{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비지도학습 감성분석 - Lexicon 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordnet Synset 및 SentiSysnset 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ka556\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = 'fly'\n",
    "synsets = wordnet.synsets(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### name: fly.n.01 #####\n",
      "POS: noun.animal\n",
      "정의: two-winged insects characterized by active flight\n",
      "표제어: ['fly']\n",
      "##### name: tent-fly.n.01 #####\n",
      "POS: noun.artifact\n",
      "정의: flap consisting of a piece of canvas that can be drawn back to provide entrance to a tent\n",
      "표제어: ['tent-fly', 'rainfly', 'fly_sheet', 'fly', 'tent_flap']\n",
      "##### name: fly.n.03 #####\n",
      "POS: noun.artifact\n",
      "정의: an opening in a garment that is closed by a zipper or by buttons concealed under a fold of cloth\n",
      "표제어: ['fly', 'fly_front']\n",
      "##### name: fly.n.04 #####\n",
      "POS: noun.act\n",
      "정의: (baseball) a hit that flies up in the air\n",
      "표제어: ['fly', 'fly_ball']\n",
      "##### name: fly.n.05 #####\n",
      "POS: noun.artifact\n",
      "정의: fisherman's lure consisting of a fishhook decorated to look like an insect\n",
      "표제어: ['fly']\n",
      "##### name: fly.v.01 #####\n",
      "POS: verb.motion\n",
      "정의: travel through the air; be airborne\n",
      "표제어: ['fly', 'wing']\n",
      "##### name: fly.v.02 #####\n",
      "POS: verb.motion\n",
      "정의: move quickly or suddenly\n",
      "표제어: ['fly']\n",
      "##### name: fly.v.03 #####\n",
      "POS: verb.motion\n",
      "정의: operate an airplane\n",
      "표제어: ['fly', 'aviate', 'pilot']\n",
      "##### name: fly.v.04 #####\n",
      "POS: verb.contact\n",
      "정의: transport by aeroplane\n",
      "표제어: ['fly']\n",
      "##### name: fly.v.05 #####\n",
      "POS: verb.motion\n",
      "정의: cause to fly or float\n",
      "표제어: ['fly']\n",
      "##### name: fly.v.06 #####\n",
      "POS: verb.motion\n",
      "정의: be dispersed or disseminated\n",
      "표제어: ['fly']\n",
      "##### name: fly.v.07 #####\n",
      "POS: verb.change\n",
      "정의: change quickly from one emotional state to another\n",
      "표제어: ['fly']\n",
      "##### name: fly.v.08 #####\n",
      "POS: verb.motion\n",
      "정의: pass away rapidly\n",
      "표제어: ['fly', 'fell', 'vanish']\n",
      "##### name: fly.v.09 #####\n",
      "POS: verb.motion\n",
      "정의: travel in an airplane\n",
      "표제어: ['fly']\n",
      "##### name: fly.v.10 #####\n",
      "POS: verb.perception\n",
      "정의: display in the air or cause to float\n",
      "표제어: ['fly']\n",
      "##### name: flee.v.01 #####\n",
      "POS: verb.motion\n",
      "정의: run away quickly\n",
      "표제어: ['flee', 'fly', 'take_flight']\n",
      "##### name: fly.v.12 #####\n",
      "POS: verb.motion\n",
      "정의: travel over (an area of land or sea) in an aircraft\n",
      "표제어: ['fly']\n",
      "##### name: fly.v.13 #####\n",
      "POS: verb.contact\n",
      "정의: hit a fly\n",
      "표제어: ['fly']\n",
      "##### name: vanish.v.05 #####\n",
      "POS: verb.change\n",
      "정의: decrease rapidly and disappear\n",
      "표제어: ['vanish', 'fly', 'vaporize']\n",
      "##### name: fly.s.01 #####\n",
      "POS: adj.all\n",
      "정의: (British informal) not to be deceived or hoodwinked\n",
      "표제어: ['fly']\n"
     ]
    }
   ],
   "source": [
    "for synset in synsets:\n",
    "    print(f'##### name: {synset.name()} #####')\n",
    "    print('POS:',synset.lexname())\n",
    "    print('정의:',synset.definition())\n",
    "    print('표제어:',synset.lemma_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 어휘간의 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiger.n.01 a fierce or audacious person\n",
      "tiger.n.02 large feline of forests in most of Asia having a tawny coat with black stripes; endangered\n"
     ]
    }
   ],
   "source": [
    "# 단어, 품사를 모를 경우에는 synsets()으로 알아냄\n",
    "for synset in wordnet.synsets('tiger'):\n",
    "    print(synset.name(),synset.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어, 품사를 아는 경우에는 synset()\n",
    "tiger = wordnet.synset('tiger.n.02')\n",
    "tree = wordnet.synset('tree.n.01')\n",
    "lion = wordnet.synset('lion.n.01')\n",
    "cat = wordnet.synset('cat.n.01')\n",
    "dog= wordnet.synset('dog.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3333333333333333, 0.16666666666666666, 0.07142857142857142)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어간의 유사도\n",
    "tiger.path_similarity(lion),tiger.path_similarity(dog),tiger.path_similarity(tree),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5개 단어간의 유사도\n",
    "similaities = []\n",
    "entities = [tiger, tree, lion, cat, dog]\n",
    "for entity in entities:\n",
    "    similarity = [entity.path_similarity(another) for another in entities]\n",
    "    similaities.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tiger</th>\n",
       "      <th>tree</th>\n",
       "      <th>lion</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tiger</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lion</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tiger      tree      lion       cat       dog\n",
       "tiger  1.000000  0.071429  0.333333  0.250000  0.166667\n",
       "tree   0.071429  1.000000  0.071429  0.076923  0.125000\n",
       "lion   0.333333  0.071429  1.000000  0.250000  0.166667\n",
       "cat    0.250000  0.076923  0.250000  1.000000  0.200000\n",
       "dog    0.166667  0.125000  0.166667  0.200000  1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(similaities, columns=['tiger', 'tree', 'lion', 'cat', 'dog'], index=['tiger', 'tree', 'lion', 'cat', 'dog'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet\n",
    "senti_synsets = list(sentiwordnet.senti_synsets('slow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SentiSynset('decelerate.v.01'),\n",
       " SentiSynset('slow.v.02'),\n",
       " SentiSynset('slow.v.03'),\n",
       " SentiSynset('slow.a.01'),\n",
       " SentiSynset('slow.a.02'),\n",
       " SentiSynset('dense.s.04'),\n",
       " SentiSynset('slow.a.04'),\n",
       " SentiSynset('boring.s.01'),\n",
       " SentiSynset('dull.s.08'),\n",
       " SentiSynset('slowly.r.01'),\n",
       " SentiSynset('behind.r.03')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti_synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 1.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# father 단어의 긍정/부정/객관성 지수\n",
    "father = sentiwordnet.senti_synset('father.n.01')\n",
    "father.pos_score(), father.neg_score(), father.obj_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 1.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mother 단어의 긍정/부정/객관성 지수\n",
    "mother = sentiwordnet.senti_synset('mother.n.01')\n",
    "mother.pos_score(), mother.neg_score(), mother.obj_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.875, 0.125, 0.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fabulous 단어의 긍정/부정/객관성 지수\n",
    "fabulous = sentiwordnet.senti_synset('fabulous.a.01')\n",
    "fabulous.pos_score(), fabulous.neg_score(), fabulous.obj_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.0, 0.5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# love 단어의 긍정/부정/객관성 지수\n",
    "love = sentiwordnet.senti_synset('love.v.01')\n",
    "love.pos_score(), love.neg_score(), love.obj_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('n', 'a', 'r', 'v')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet.NOUN, wordnet.ADJ, wordnet.ADV, wordnet.VERB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 감성지수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It', \"'s\", 'good', 'to', 'see', 'you', 'again', '.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "sentence = \"It's good to see you again.\"\n",
    "word_list = word_tokenize(sentence)\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('good', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('see', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('again', 'RB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penn_to_wordnet(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    if tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    if tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    if tag.startswith('N'):\n",
    "        return wordnet.NOUN     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It -> None\n",
      "'s -> v\n",
      "good -> a\n",
      "to -> None\n",
      "see -> v\n",
      "you -> None\n",
      "again -> r\n",
      ". -> None\n"
     ]
    }
   ],
   "source": [
    "for word, pos in pos_tag(word_list):\n",
    "    print(word,\"->\",penn_to_wordnet(pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sentence로부터 감성지수를 계산하는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good', 'see', 'you', 'again']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"It's good to see you again.\"\n",
    "word_list = [ word for word in word_tokenize(sentence) if len(word) > 2 ]\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<good.a.01: PosScore=0.75 NegScore=0.0>\n",
      "<see.n.01: PosScore=0.0 NegScore=0.0>\n",
      "<again.r.01: PosScore=0.0 NegScore=0.0>\n"
     ]
    }
   ],
   "source": [
    "for word, pos in pos_tag(word_list):\n",
    "    wn_tag = penn_to_wordnet(pos)\n",
    "    if wn_tag:          # None이 아닌 현재는 n a r v\n",
    "        synsets = list(sentiwordnet.senti_synsets(word, wn_tag))\n",
    "        synset = synsets[0]\n",
    "        print(synset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = 0\n",
    "for word, pos in pos_tag(word_list):\n",
    "    wn_tag = penn_to_wordnet(pos)\n",
    "    if wn_tag:          \n",
    "        synsets = list(sentiwordnet.senti_synsets(word, wn_tag))\n",
    "        synset = synsets[0]\n",
    "        # print(type(synset.pos_score()),type(synset.pos_score()), type(sentiment))\n",
    "        sentiment += synset.pos_score() - synset.neg_score()\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 표제어 추출까지 고려\n",
    "sentiment = 0\n",
    "for word, pos in pos_tag(word_list):\n",
    "    wn_tag = penn_to_wordnet(pos)\n",
    "    if wn_tag:\n",
    "        lemma = lemmatizer.lemmatize(word, wn_tag)\n",
    "        synsets = list(sentiwordnet.senti_synsets(word, wn_tag))\n",
    "        synset = synsets[0]\n",
    "        sentiment += synset.pos_score() - synset.neg_score()\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 도큐먼트에서 감성지수를 계산하는 과정 및 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "document = '''This is a movie made purely to satisfy the fans and there should be no doubt about that.\n",
    "No Way Home, in my opinion, is even better than Homecoming and Far From Home, and pretty much one of the best MCU movies of all time.\n",
    "It's a simple story, but the execution is fantastic. Even the smallest of surprises have a huge impact,\n",
    "and I could feel that in the theatre as I joined several other Spider-Man fans cheer out for both heroes and villains.\n",
    "The action sequences were brilliant;\n",
    "seeing them in 3D is totally worth the price of admission. Every actor delivered a believable, realistic performance,\n",
    "and especially our lead actor Tom Holland.\n",
    "The visual effects too were top notch and the editing was stupendous.\n",
    "Two and a half hours flew by real quick while watching this popcorn action entertainer.\n",
    "It won't be fair to reveal anything, so here I conclude my review,\n",
    "and recommend you to check out this new world of Spidey-ness on the big screen and in 3D.\n",
    "And once you've seen it, please don't spoil it for others, just like you won't want it spoiled for yourself.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homecoming\n",
      "From\n",
      "MCU\n",
      "Spider-Man\n",
      "lead\n",
      "popcorn\n",
      "n't\n",
      "anything\n",
      "Spidey-ness\n",
      "'ve\n",
      "n't\n",
      "others\n",
      "n't\n",
      "긍정\n"
     ]
    }
   ],
   "source": [
    "sentiment = 0.0\n",
    "for sentence in sent_tokenize(document):\n",
    "    word_list = [ word for word in word_tokenize(sentence) if len(word) > 2 ]\n",
    "    for word, pos in pos_tag(word_list):\n",
    "        wn_tag = penn_to_wordnet(pos)\n",
    "        if wn_tag:\n",
    "            lemma = lemmatizer.lemmatize(word, wn_tag)\n",
    "            synsets = list(sentiwordnet.senti_synsets(word, wn_tag))\n",
    "            if not synsets:\n",
    "                print(word)\n",
    "                continue\n",
    "            synset = synsets[0]\n",
    "            sentiment += synset.pos_score() - synset.neg_score()\n",
    "print('긍정' if sentiment >= 0 else '부정')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swn_polarity(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    sentiment = 0.0\n",
    "    for sentence in sent_tokenize(text):\n",
    "        word_list = [ word for word in word_tokenize(sentence) if len(word) > 2 ]\n",
    "        for word, pos in pos_tag(word_list):\n",
    "            wn_tag = penn_to_wordnet(pos)\n",
    "            if wn_tag:\n",
    "                lemma = lemmatizer.lemmatize(word, wn_tag)\n",
    "                synsets = list(sentiwordnet.senti_synsets(word, wn_tag))\n",
    "                if not synsets:\n",
    "                    # print(word)\n",
    "                    continue\n",
    "                synset = synsets[0]\n",
    "                sentiment += synset.pos_score() - synset.neg_score()\n",
    "    return 1 if sentiment >= 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IMDB 영화평 감성분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/labeledTrainData.tsv', sep='\\t', quoting=3)    # 3: QUOTE_NONE\n",
    "display(df.head(3))\n",
    "# <br />(: 줄바꿈) 태그는 공백으로 변환\n",
    "df.review = df.review.str.replace('<br />','')\n",
    "# 구둣점, 숫자 제거 - 영문자가 아닌 글자는 공백으로 변경\n",
    "# 데이터프레임의 str method는 정규표현식을 지원함\n",
    "df.review = df.review.str.replace('[^A-Za-z]',' ').str.strip()\n",
    "df.review[0][:1000]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred'] = df.review.apply(lambda x: swn_polarity(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6308"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도 계산\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(df.sentiment, df.pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VADER Lexicon을 이용한 감성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.13, 'neu': 0.743, 'pos': 0.127, 'compound': -0.7943}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "senti_analyzer = SentimentIntensityAnalyzer()\n",
    "senti_analyzer.polarity_scores(df. review[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_polarity(document, threshold=0.1):\n",
    "    score = senti_analyzer.polarity_scores(document)\n",
    "    return 1 if score['compound'] >= threshold else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vader'] = df.review.apply(lambda x: vader_polarity(x, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7005"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df.sentiment, df.vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "becefdacc5f1c94720c81594b94a76de7b81d1f18fcb450ac2dbe2941d580a00"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('kdig')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
